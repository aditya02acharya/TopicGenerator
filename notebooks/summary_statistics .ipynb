{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f730a6b3",
   "metadata": {},
   "source": [
    "# Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85581bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tableone import TableOne\n",
    "\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/MobileAppReviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column to datetime\n",
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23617d4",
   "metadata": {},
   "source": [
    "# Generate Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c681941",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_apps = df[\"app_id\"].nunique()\n",
    "unique_genre = df[\"genre\"].unique()\n",
    "study_start = df[\"time\"].min()\n",
    "study_end = df[\"time\"].max()\n",
    "\n",
    "print(f\"Number of apps reviewed: {unique_apps} \\n\")\n",
    "print(f\"Number App categories: {len(unique_genre)} \\n\")\n",
    "print(f\"App categories: {unique_genre} \\n\")\n",
    "print(f\"App data collected between {study_start} to {study_end} \\n\")\n",
    "print(f\"Number of missing reviews: {df['reviews_text'].isna().sum()} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf0aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = df['user_name'].nunique()\n",
    "unknown_users = len(df[df[\"user_name\"] == \"A Google user\"])\n",
    "total_reviews = len(df)\n",
    "mean = df['scores'].mean()\n",
    "\n",
    "df[\"unknown_user\"] = 0\n",
    "df.loc[df[\"user_name\"] == \"A Google user\", \"unknown_user\"] = 1\n",
    "dup = df[df[\"unknown_user\"] == 0].groupby(\"app_id\").agg({\"unknown_user\": \"sum\"})\n",
    "repreated_review = max(dup[\"unknown_user\"].values)\n",
    "\n",
    "print(f\"Total textual reviews: {total_reviews} \\n\")\n",
    "print(f\"Total unique users: {unique_users} \\n\")\n",
    "print(f\"Total unknown users: {unknown_users} \\n\")\n",
    "print(f\"Total users who gave multiple reviews: {total_reviews - unique_users - unknown_users}\")\n",
    "print(f\"Average rating for all apps based on the reviews: {round(mean,2)} \\n\")\n",
    "print(f\"Repeated reviews per app: {repreated_review} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ebbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the review score distribution.\n",
    "ax = sns.countplot(x='scores', data=df, palette=\"pastel\")\n",
    "plt.savefig(\"../reports/figures/score_dist_plot.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c220767f",
   "metadata": {},
   "source": [
    "# Generate Summary Measures of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b81a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['genre','unknown_user', 'scores']\n",
    "\n",
    "categorical = ['genre','unknown_user']\n",
    "\n",
    "groupby = 'unknown_user'\n",
    "\n",
    "nonnormal = ['scores']\n",
    "\n",
    "mytable = TableOne(df, columns, categorical, groupby, nonnormal, pval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f82cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mytable.tabulate(tablefmt = \"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfdf528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the year when the review what given.\n",
    "df['time_year'] = df['time'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7398e3",
   "metadata": {},
   "source": [
    "# Exploring yearly trend for reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8818a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate yearly count for each app genre.\n",
    "yearly_count = df.groupby(['genre', 'time_year']).count().reset_index()\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(yearly_count.pivot(\"genre\", \"time_year\", \"scores\"), annot=False, cmap='crest')\n",
    "plt.savefig(\"../reports/figures/score_time_dist_plot.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcdfcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate yearly geometric mean (yearly samples could be low and median maybe biased) for each app genre. \n",
    "review_yearly = df.groupby(['genre', 'time_year']).scores.apply(stats.gmean).reset_index()\n",
    "plt.subplots(figsize=(20,15))\n",
    "sns.heatmap(review_yearly.pivot(\"genre\", \"time_year\", \"scores\"), annot=False, cmap='crest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc616dca",
   "metadata": {},
   "source": [
    "# Word Count distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ae119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import emoji\n",
    "import unicodedata\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "    return str(text).lower()\n",
    "\n",
    "def word_expansion(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def text_formatter(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub(r'\\\\\\w', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "        \n",
    "def to_string(text):\n",
    "    # Convert list to string\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def text_preprocessing(text, expand_contraction = True):\n",
    "    # 1. Convert words to lower case\n",
    "    text = to_lower(text)\n",
    "    \n",
    "    # 2. Expand contractions\n",
    "    if expand_contraction:\n",
    "        text = word_expansion(text)\n",
    "\n",
    "    # 3. Format words and remove unwanted characters\n",
    "    text = text_formatter(text)\n",
    "    \n",
    "    # 4. Tokenize each word\n",
    "    text = nltk.WordPunctTokenizer().tokenize(text)\n",
    "    \n",
    "    # Lemmatize each word\n",
    "    text = [nltk.stem.WordNetLemmatizer().lemmatize(token, pos='v') for token in text if len(token)>1]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24baeac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_text_clean_list'] = df[\"reviews_text\"].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Token Length\"] = df['reviews_text_clean_list'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(x='Token Length', data=df, palette=\"pastel\")\n",
    "ax.set(xlim=(0, 125))\n",
    "plt.savefig(\"../reports/figures/len_dist_plot.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd5c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
