{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f42930",
   "metadata": {},
   "source": [
    "# Import Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b3891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import emoji\n",
    "import contractions\n",
    "import nltk\n",
    "import gensim\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.cluster import KMeansClusterer, cosine_distance\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "import hdbscan\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd240b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/MobileAppReviews.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771d39c",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "    return str(text).lower()\n",
    "\n",
    "def word_expansion(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def text_formatter(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub(r'\\\\\\w', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "        \n",
    "def to_string(text):\n",
    "    # Convert list to string\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def text_preprocessing(text, expand_contraction = True):\n",
    "    # 1. Convert words to lower case\n",
    "    text = to_lower(text)\n",
    "    \n",
    "    # 2. Expand contractions\n",
    "    if expand_contraction:\n",
    "        text = word_expansion(text)\n",
    "\n",
    "    # 3. Format words and remove unwanted characters\n",
    "    text = text_formatter(text)\n",
    "    \n",
    "    # 4. Tokenize each word\n",
    "    text = nltk.WordPunctTokenizer().tokenize(text)\n",
    "    \n",
    "    # Lemmatize each word\n",
    "    text = [nltk.stem.WordNetLemmatizer().lemmatize(token, pos='v') for token in text if len(token)>1]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_text_clean_list'] = df[\"reviews_text\"].apply(text_preprocessing)\n",
    "df['reviews_text_clean'] = df[\"reviews_text\"].apply(to_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list.extend(['app', 'phone', 'work', 'time', 'use', 'get'])\n",
    "df['reviews_text_clean_list'] = [[word for word in line if word not in stopwords_list] for line in df['reviews_text_clean_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4881d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"token_len\"] = df['reviews_text_clean_list'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter reviews with 5 tokens or more\n",
    "df = df[df[\"token_len\"] >= 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47b8246",
   "metadata": {},
   "source": [
    "# Topic Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec72e0",
   "metadata": {},
   "source": [
    "## 1. Embedding: Sentence to Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f433af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['reviews_text_clean'].values\n",
    "model = SentenceTransformer('all-distilroberta-v1')\n",
    "embeddings = model.encode(data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74161c9",
   "metadata": {},
   "source": [
    "## 2. Dimentionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bcb4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_embeddings = umap.UMAP(n_neighbors=15, \n",
    "                            n_components=10, \n",
    "                            metric='cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a97eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_embeddings_viz = umap.UMAP(n_neighbors=15,\n",
    "                               n_components=2,\n",
    "                               metric='cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b42a6",
   "metadata": {},
   "source": [
    "## 3. Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbefd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = hdbscan.HDBSCAN(min_cluster_size=100,\n",
    "                          metric='euclidean', cluster_selection_method='eom',).fit(map_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af0d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(cluster.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e669f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(data_2d, cluster_labels):\n",
    "    result = pd.DataFrame(data_2d, columns=['x', 'y'])\n",
    "    result['labels'] = cluster_labels\n",
    "    outliers = result.loc[result.labels == -1, :]\n",
    "    clustered = result.loc[result.labels != -1, :]\n",
    "    plt.figure()\n",
    "    plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)\n",
    "    plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [30, 20]\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plot_clusters(map_embeddings_viz, cluster.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf62a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic_id'] = cluster.labels_\n",
    "df['contribution'] = cluster.probabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['app_id', 'genre', 'user_name', 'reviews_text', 'scores', 'time', 'topic_id', 'contribution']].to_csv(\"../data/processed_data_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Tuning\n",
    "df['reviews_clean'] = df[\"reviews_text_clean_list\"].apply(to_string)\n",
    "\n",
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "\n",
    "def extract_top_n_words_per_topic(tf_idf, count, reviews_per_class, n=10):\n",
    "    words = count.get_feature_names_out()\n",
    "    labels = list(reviews_per_class['topic_id'])\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "scores_list = {}\n",
    "for i in tqdm(range(60, 160, 10)):\n",
    "    cluster = hdbscan.HDBSCAN(min_cluster_size=i, metric='euclidean', cluster_selection_method='eom',).fit(map_embeddings)\n",
    "    df['topic_id'] = cluster.labels_\n",
    "    reviews_per_class = df.groupby(['topic_id'], as_index = False).agg({'reviews_clean': ' '.join})\n",
    "    tf_idf, count = c_tf_idf(reviews_per_class.reviews_clean.values, m=len(df))\n",
    "    top_n_words = extract_top_n_words_per_topic(tf_idf, count, reviews_per_class, n=5)\n",
    "    topics = []\n",
    "    for topic_list in top_n_words.values():\n",
    "        topics.append(list(map(lambda x: x[0], topic_list)))\n",
    "    \n",
    "    dictionary = gensim.corpora.Dictionary(df['reviews_text_clean_list'])\n",
    "    cm = gensim.models.CoherenceModel(topics=topics, texts=df['reviews_text_clean_list'], \n",
    "                                      dictionary=dictionary, \n",
    "                                      coherence='c_v')\n",
    "    coherence_score = cm.get_coherence()\n",
    "    scores_list[i] = coherence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8d43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
