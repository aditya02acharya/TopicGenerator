{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c497d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import contractions\n",
    "\n",
    "import matplotlib.patheffects as path_effects\n",
    "import nltk\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "nltk.download(['stopwords', 'wordnet', 'omw-1.4', 'averaged_perceptron_tagger', 'vader_lexicon'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import emoji\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed_data_new.csv\")\n",
    "#df = df[~df[\"topic_id\"].isin([-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c747d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "    return str(text).lower()\n",
    "\n",
    "def word_expansion(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def text_formatter(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub(r'\\\\\\w', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "        \n",
    "def to_string(text):\n",
    "    # Convert list to string\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def text_preprocessing(text, expand_contraction = True):\n",
    "    # 1. Convert words to lower case\n",
    "    text = to_lower(text)\n",
    "    \n",
    "    # 2. Expand contractions\n",
    "    if expand_contraction:\n",
    "        text = word_expansion(text)\n",
    "\n",
    "    # 3. Format words and remove unwanted characters\n",
    "    text = text_formatter(text)\n",
    "    \n",
    "    # 4. Tokenize each word\n",
    "    text = nltk.WordPunctTokenizer().tokenize(text)\n",
    "    \n",
    "    # Lemmatize each word\n",
    "    text = [nltk.stem.WordNetLemmatizer().lemmatize(token, pos='v') for token in text if len(token)>1]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = range(len(df))\n",
    "df['reviews_clean_list'] = df[\"reviews_text\"].apply(text_preprocessing)\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list.extend(['app', 'phone', 'work', 'time', 'use', 'get'])\n",
    "\n",
    "df['reviews_clean_list'] = [[word for word in line if word not in stopwords_list] \\\n",
    "                                           for line in df['reviews_clean_list']]\n",
    "df['reviews_clean'] = df[\"reviews_clean_list\"].apply(to_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866311ff",
   "metadata": {},
   "source": [
    "# Generate Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39521e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_words = ','.join(list(df['reviews_clean'].values))\n",
    "wordcloud = WordCloud(background_color=\"white\",\n",
    "                      max_words= 200,\n",
    "                      contour_width = 8,\n",
    "                      contour_color = \"steelblue\",\n",
    "                      collocations=False).generate(review_words)\n",
    "                      \n",
    "# Visualize the word cloud\n",
    "fig = plt.figure(1, figsize = (10, 10))\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fbfeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in df['genre'].unique():\n",
    "    review_words = ','.join(list(df[df['genre'] == cat]['reviews_clean'].values))\n",
    "    # Generate the word cloud\n",
    "    wordcloud = WordCloud(background_color=\"white\",\n",
    "                      max_words= 200,\n",
    "                      contour_width = 8,\n",
    "                      contour_color = \"steelblue\",\n",
    "                      collocations=False).generate(review_words)\n",
    "    # Visualize the word cloud\n",
    "    fig = plt.figure(1, figsize = (10, 10))\n",
    "    plt.title(cat)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud)\n",
    "    filename = \"../reports/figures/\"+cat+\".png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df6f06",
   "metadata": {},
   "source": [
    "# Topic Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea88d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_per_class = df.groupby(['topic_id'], as_index = False).agg({'reviews_clean': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate term frequency and Inverse document frequency\n",
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "  \n",
    "tf_idf, count = c_tf_idf(reviews_per_class.reviews_clean.values, m=len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_n_words_per_topic(tf_idf, count, reviews_per_class, n=10):\n",
    "    words = count.get_feature_names_out()\n",
    "    labels = list(reviews_per_class['topic_id'])\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, reviews_per_class, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e91b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['topic_id'])\n",
    "                     .reviews_clean\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"topic_id\": \"Topic ID\", \"reviews_clean\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes\n",
    "\n",
    "topic_sizes = extract_topic_sizes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1911d3",
   "metadata": {},
   "source": [
    "# Coherence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for topic_list in top_n_words.values():\n",
    "    topics.append(list(map(lambda x: x[0], topic_list)))\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(df['reviews_clean_list'])\n",
    "\n",
    "cm = gensim.models.CoherenceModel(topics=topics, texts=df['reviews_clean_list'], \n",
    "                                  dictionary=dictionary, \n",
    "                                  coherence='c_v')\n",
    "\n",
    "coherence_score = cm.get_coherence()\n",
    "print(coherence_score)\n",
    "coherence_score_per_topic = cm.get_coherence_per_topic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_str = ['\\n '.join(t[:2]) for t in topics]\n",
    "data_topic_score = pd.DataFrame(data=zip(topics_str, coherence_score_per_topic), columns=['Topic', 'Coherence'])\n",
    "\n",
    "plt.subplots(figsize=(5,30))\n",
    "sns.barplot(x=\"Coherence\", y=\"Topic\", data=data_topic_score, color=\"b\", ci=None)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a4f28",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98984f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_positive(text):\n",
    "    \"\"\"True if review has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(text)[\"pos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba118d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos_sentiment\"] = df[\"reviews_clean\"].apply(is_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd562bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "result = df.groupby([\"topic_id\"])['pos_sentiment'].aggregate(np.mean).reset_index().sort_values('pos_sentiment').head(20)\n",
    "sns.barplot(x='topic_id', y=\"pos_sentiment\", data=result, order=result['topic_id'], palette=\"pastel\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig(\"../reports/figures/sentiment_dist_plot.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9672a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a79a3be",
   "metadata": {},
   "source": [
    "# User Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[\"topic_id\"].sort_values().unique():\n",
    "    print(i, top_n_words[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in result[\"topic_id\"].unique():\n",
    "    wrd_list = top_n_words[i]\n",
    "    df_list += list(map(lambda x: (i, x[0], x[1]), wrd_list))\n",
    "df_top_topics = pd.DataFrame(df_list, columns =['topic_id', 'word', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_id in result[\"topic_id\"].unique():\n",
    "    sizes = df_top_topics[df_top_topics['topic_id'] == group_id]['score'].values[:10]\n",
    "    label = df_top_topics[df_top_topics['topic_id'] == group_id]['word'].values[:10]\n",
    "    ax = squarify.plot(sizes=sizes, label=label, alpha=0.6).set(title=f'Topic ID: {group_id}')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"../reports/figures/top5_dist_{group_id}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d99dd",
   "metadata": {},
   "source": [
    "# User Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[16, 0, 32, 7, 1, 33, 34, 35, 31]\n",
    "csf_df = df[~df['topic_id'].isin([16, 0, 32, 7, 1, 33, 34, 35, 31, 13, 12])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80fd814",
   "metadata": {},
   "outputs": [],
   "source": [
    "csf_df[\"Usability\"] = 0\n",
    "csf_df[\"Online Service\"] = 0\n",
    "csf_df[\"Biometric Auth\"] = 0\n",
    "csf_df[\"Linked Services\"] = 0\n",
    "csf_df[\"Payments\"] = 0\n",
    "csf_df[\"Software Issue\"] = 0\n",
    "csf_df[\"Information\"] = 0\n",
    "csf_df[\"Authentication\"] = 0\n",
    "csf_df[\"Documents\"] = 0\n",
    "csf_df[\"Account Access\"] = 0\n",
    "\n",
    "\n",
    "csf_df.loc[csf_df[\"topic_id\"].isin([17]), \"Usability\"] = 1\n",
    "csf_df.loc[csf_df[\"topic_id\"].isin([2, 30, 10]), \"Online Service\"] = 1\n",
    "csf_df.loc[csf_df[\"topic_id\"].isin([19]), \"Biometric Auth\"] = 1\n",
    "csf_df.loc[csf_df[\"topic_id\"].isin([9, 14, 3]), \"Linked Services\"] = 1\n",
    "csf_df.loc[csf_df[\"topic_id\"].isin([13, 12]), \"Payments\"] = 1\n",
    "csf_df.loc[csf_df[\"topic_id\"].isin([-1, 25, 23, 21, 32, 22, 24, 7]), \"Software Issue\"] = 1\n",
    "csf_df.loc[csf_df[\"topic_id\"].isin([5]), \"Information\"] = 1\n",
    "csf_df.loc[csf_df[\"topic_id\"].isin([20, 27, 18, 26]), \"Authentication\"] = 1\n",
    "csf_df.loc[csf_df[\"topic_id\"].isin([15, 29]), \"Documents\"] = 1\n",
    "csf_df.loc[csf_df[\"topic_id\"].isin([8]), \"Account Access\"] = 1\n",
    "\n",
    "#csf_df[\"intercept\"] = 1\n",
    "csf_df[\"binary_scores\"] = 0\n",
    "csf_df.loc[csf_df[\"scores\"].isin([4, 5]), \"binary_scores\"] = 1\n",
    "csf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be453414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define predictor and response variables\n",
    "x = csf_df[['Usability', 'Online Service', 'Biometric Auth',\n",
    "       'Linked Services', 'Software Issue', 'Information',\n",
    "       'Authentication', 'Documents', 'Account Access']]\n",
    "y = csf_df['binary_scores']\n",
    "\n",
    "binomial_model = sm.GLM(y, sm.add_constant(x), family=sm.families.Binomial())\n",
    "\n",
    "binomial_results = binomial_model.fit()\n",
    "\n",
    "print(binomial_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967ccd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
