{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import contractions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "import matplotlib.patheffects as path_effects\n",
    "import nltk\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "    return str(text).lower()\n",
    "\n",
    "def word_expansion(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def text_formatter(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub(r'\\\\\\w', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "        \n",
    "def to_string(text):\n",
    "    # Convert list to string\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def text_preprocessing(text, expand_contraction = True):\n",
    "    # 1. Convert words to lower case\n",
    "    text = to_lower(text)\n",
    "    \n",
    "    # 2. Expand contractions\n",
    "    if expand_contraction:\n",
    "        text = word_expansion(text)\n",
    "\n",
    "    # 3. Format words and remove unwanted characters\n",
    "    text = text_formatter(text)\n",
    "    \n",
    "    # 4. Tokenize each word\n",
    "    text = nltk.WordPunctTokenizer().tokenize(text)\n",
    "    \n",
    "    # Lemmatize each word\n",
    "    text = [nltk.stem.WordNetLemmatizer().lemmatize(token, pos='v') for token in text if len(token)>1]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afa986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/MobileAppReviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1951f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_text_clean_list'] = df[\"reviews_text\"].apply(text_preprocessing)\n",
    "df['reviews_text_clean'] = df[\"reviews_text_clean_list\"].apply(to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e58651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join  text together\n",
    "review_words = ','.join(list(df['reviews_text_clean'].values))\n",
    "\n",
    "# Count each word\n",
    "counter = Counter(review_words.split())\n",
    "most_frequent = counter.most_common(30)\n",
    "\n",
    "fig = plt.figure(1, figsize = (20,10))\n",
    "_ = pd.DataFrame(most_frequent, columns=(\"words\",\"count\"))\n",
    "sns.barplot(x = 'words', y = 'count', data = _, palette = 'winter')\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list.extend(['app', 'phone', 'work', 'time', 'use', 'get'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47041099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_text_clean_list'] = [[word for word in line if word not in stopwords_list] for line in df['reviews_text_clean_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2339a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_text_clean'] = df[\"reviews_text_clean_list\"].apply(to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join  text together\n",
    "review_words = ','.join(list(df['reviews_text_clean'].values))\n",
    "\n",
    "# Count each word\n",
    "counter = Counter(review_words.split())\n",
    "most_frequent = counter.most_common(50)\n",
    "\n",
    "# Bar plot of frequent words\n",
    "fig = plt.figure(1, figsize = (20,10))\n",
    "_ = pd.DataFrame(most_frequent, columns=(\"words\",\"count\"))\n",
    "sns.barplot(x = 'words', y = 'count', data = _, palette = 'winter')\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(background_color=\"white\",\n",
    "                      max_words= 200,\n",
    "                      contour_width = 8,\n",
    "                      contour_color = \"steelblue\",\n",
    "                      collocations=False).generate(review_words)\n",
    "                      \n",
    "# Visualize the word cloud\n",
    "fig = plt.figure(1, figsize = (10, 10))\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in df['genre'].unique():\n",
    "    review_words = ','.join(list(df[df['genre'] == cat]['reviews_text_clean'].values))\n",
    "    # Generate the word cloud\n",
    "    wordcloud = WordCloud(background_color=\"white\",\n",
    "                      max_words= 200,\n",
    "                      contour_width = 8,\n",
    "                      contour_color = \"steelblue\",\n",
    "                      collocations=False).generate(review_words)\n",
    "    # Visualize the word cloud\n",
    "    fig = plt.figure(1, figsize = (10, 10))\n",
    "    plt.title(cat)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud)\n",
    "    filename = \"../reports/figures/\"+cat+\".png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "dictionary = gensim.corpora.Dictionary(df['reviews_text_clean_list'])\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [dictionary.doc2bow(text) for text in df['reviews_text_clean_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "number_of_topics = []\n",
    "coherence_score = []\n",
    "for i in range(1,30):\n",
    "    lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                id2word=dictionary,\n",
    "                                                iterations=800,\n",
    "                                                num_topics=i)\n",
    "    \n",
    "    coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, \n",
    "                                                       texts=df['reviews_text_clean_list'], \n",
    "                                                       dictionary=dictionary, \n",
    "                                                       coherence='c_v')\n",
    "    \n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    \n",
    "    number_of_topics.append(i)\n",
    "    \n",
    "    coherence_score.append(coherence_lda);\n",
    "\n",
    "# Create a dataframe of coherence score by number of topics \n",
    "topic_coherence = pd.DataFrame({'number_of_topics':number_of_topics,\n",
    "                                'coherence_score':coherence_score})\n",
    "\n",
    "# Print a line plot\n",
    "sns.set_context(\"talk\")\n",
    "ax = sns.lineplot(data=topic_coherence, x='number_of_topics', y='coherence_score')\n",
    "plt.savefig(\"../reports/figures/coherence_plot.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of topics \n",
    "n_topics = 20\n",
    "\n",
    "# Run the LDA model\n",
    "lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=n_topics, random_state=100, \n",
    "                                                    chunksize=10, passes=10, alpha='symmetric', iterations=1000,\n",
    "                                                    per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a917888",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} Word: {}\".format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b30f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
